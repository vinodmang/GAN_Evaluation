{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A metric approach to differentiate real data distribution from  synthetic data distribution generated by using the CycleGAN generator. A pretrained network is used as a feature extractor and the activations on the terminal node are used to model a gaussian distribution for each domain. The distance between the distributions is computed as the metric. \n",
    "\n",
    "The distance calculated by the metric is the wassertien distance (P-Q) between the real(P) and synthetic(Q) distributions. When the samples are very large the reflexive distance (P-P) should ideally be close to zero. In this notebook using limited samples this distance ( using method calculate_score(P, P) aka baseline score) is used as a placeholder baseline to compare with P-Q distance (calculate_score(P, Q) aka cross domain score). \n",
    "\n",
    "A couple of ways to test this metric:\n",
    "(1) Check if the metric calculate_score(P, Q) decreases as the GAN training progresses and the synthetic distribution approaches the real distribution\n",
    "(2) As the sample size increases the distance using samples from the same distribution should approch zero.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import inception_v3,VGG,AlexNet\n",
    "import torch\n",
    "from torch import nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: torchvision>=0.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (0.5.0)\n",
      "Requirement already satisfied: dominate>=2.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (2.5.1)\n",
      "Collecting visdom>=0.1.8.3 (from -r requirements.txt (line 4))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/75/e078f5a2e1df7e0d3044749089fc2823e62d029cc027ed8ae5d71fafcbdc/visdom-0.1.8.9.tar.gz (676kB)\n",
      "\u001b[K    100% |████████████████████████████████| 686kB 25.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision>=0.2.1->-r requirements.txt (line 2)) (1.15.4)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision>=0.2.1->-r requirements.txt (line 2)) (1.11.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision>=0.2.1->-r requirements.txt (line 2)) (5.4.1)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (2.20.0)\n",
      "Requirement already satisfied: tornado in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (5.0.2)\n",
      "Requirement already satisfied: pyzmq in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (17.0.0)\n",
      "Collecting jsonpatch (from visdom>=0.1.8.3->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/82/53/73ca86f2a680c705dcd1708be4887c559dfe9ed250486dd3ccd8821b8ccb/jsonpatch-1.25-py2.py3-none-any.whl\n",
      "Collecting torchfile (from visdom>=0.1.8.3->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
      "Requirement already satisfied: websocket-client in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (0.57.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (1.23)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (2.6)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch->visdom>=0.1.8.3->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/18/b0/a80d29577c08eea401659254dfaed87f1af45272899e1812d7e01b679bc5/jsonpointer-2.0-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: visdom, torchfile\n",
      "  Running setup.py bdist_wheel for visdom ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/70/19/a7/6d589ed967f4dfefd33bc166d081257bd4ed0cb618dccfd62a\n",
      "  Running setup.py bdist_wheel for torchfile ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
      "Successfully built visdom torchfile\n",
      "\u001b[31mfastai 1.0.60 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "Installing collected packages: jsonpointer, jsonpatch, torchfile, visdom\n",
      "Successfully installed jsonpatch-1.25 jsonpointer-2.0 torchfile-0.1.0 visdom-0.1.8.9\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# pre-requisites for repo - run if packages missing\n",
    "!pip install -r requirements.txt\n",
    "#Download model and dataset - ideally should use provided scripts from repo but running into cert. errors. USe alt. in next cell\n",
    "#!bash ./scripts/download_cyclegan_model.sh horse2zebra\n",
    "#!bash ./datasets/download_cyclegan_dataset.sh horse2zebra\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: timestamping does nothing in combination with -O. See the manual\n",
      "for details.\n",
      "\n",
      "--2020-06-19 18:08:11--  http://efrosgans.eecs.berkeley.edu/cyclegan/pretrained_models/horse2zebra.pth\n",
      "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.189.73\n",
      "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.189.73|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 45575747 (43M)\n",
      "Saving to: ‘./checkpoints/horse2zebra_pretrained/latest_net_G.pth’\n",
      "\n",
      "./checkpoints/horse 100%[===================>]  43.46M  19.4MB/s    in 2.2s    \n",
      "\n",
      "2020-06-19 18:08:14 (19.4 MB/s) - ‘./checkpoints/horse2zebra_pretrained/latest_net_G.pth’ saved [45575747/45575747]\n",
      "\n",
      "WARNING: timestamping does nothing in combination with -O. See the manual\n",
      "for details.\n",
      "\n",
      "--2020-06-19 18:08:14--  https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/horse2zebra.zip\n",
      "Resolving people.eecs.berkeley.edu (people.eecs.berkeley.edu)... 128.32.189.73\n",
      "Connecting to people.eecs.berkeley.edu (people.eecs.berkeley.edu)|128.32.189.73|:443... connected.\n",
      "WARNING: cannot verify people.eecs.berkeley.edu's certificate, issued by ‘CN=InCommon RSA Server CA,OU=InCommon,O=Internet2,L=Ann Arbor,ST=MI,C=US’:\n",
      "  Issued certificate has expired.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 116867962 (111M) [application/zip]\n",
      "Saving to: ‘./datasets/horse2zebra.zip’\n",
      "\n",
      "./datasets/horse2ze 100%[===================>] 111.45M  23.6MB/s    in 5.1s    \n",
      "\n",
      "2020-06-19 18:08:19 (21.8 MB/s) - ‘./datasets/horse2zebra.zip’ saved [116867962/116867962]\n",
      "\n",
      "mkdir: cannot create directory ‘./datasets/horse2zebra/’: File exists\n",
      "Archive:  ./datasets/horse2zebra.zip\n",
      "replace ./datasets/horse2zebra/trainA/n02381460_6223.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "#Alterative to download pre-trained model and dataset\n",
    "!mkdir -p ./checkpoints/horse2zebra_pretrained\n",
    "!wget http://efrosgans.eecs.berkeley.edu/cyclegan/pretrained_models/horse2zebra.pth -O ./checkpoints/horse2zebra_pretrained/latest_net_G.pth\n",
    "\n",
    "!sudo yum update -y  ca-certificates\n",
    "!wget https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/horse2zebra.zip -O ./datasets/horse2zebra.zip\n",
    "!mkdir ./datasets/horse2zebra/\n",
    "!unzip ./datasets/horse2zebra.zip -d ./datasets/\n",
    "!rm ./datasets/horse2zebra.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 1                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: datasets/horse2zebra/trainA   \t[default: None]\n",
      "             dataset_mode: single                        \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix:                               \n",
      "               n_layers_D: 3                             \n",
      "                     name: horse2zebra_pretrained        \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \t[default: False]\n",
      "                  no_flip: False                         \n",
      "                     norm: instance                      \n",
      "                    ntest: inf                           \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with normal\n",
      "model [TestModel] was created\n",
      "loading the model from ./checkpoints/horse2zebra_pretrained/latest_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.378 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/horse2zebra_pretrained/test_latest\n",
      "processing (0000)-th image... ['datasets/horse2zebra/trainA/n02381460_1001.jpg']\n",
      "processing (0005)-th image... ['datasets/horse2zebra/trainA/n02381460_1009.jpg']\n",
      "processing (0010)-th image... ['datasets/horse2zebra/trainA/n02381460_1023.jpg']\n",
      "processing (0015)-th image... ['datasets/horse2zebra/trainA/n02381460_1035.jpg']\n",
      "processing (0020)-th image... ['datasets/horse2zebra/trainA/n02381460_1048.jpg']\n",
      "processing (0025)-th image... ['datasets/horse2zebra/trainA/n02381460_1058.jpg']\n",
      "processing (0030)-th image... ['datasets/horse2zebra/trainA/n02381460_108.jpg']\n",
      "processing (0035)-th image... ['datasets/horse2zebra/trainA/n02381460_11.jpg']\n",
      "processing (0040)-th image... ['datasets/horse2zebra/trainA/n02381460_1122.jpg']\n",
      "processing (0045)-th image... ['datasets/horse2zebra/trainA/n02381460_1144.jpg']\n"
     ]
    }
   ],
   "source": [
    "#Generate synthetic data using pre-trained generator from CycleGAN repo\n",
    "!python test.py --dataroot datasets/horse2zebra/trainA --name horse2zebra_pretrained --model test --no_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class to create activations from input images using pytorch module\n",
    "class EvaluateCycleGAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pretrained_cnn = inception_v3(pretrained=True).eval()\n",
    "        \n",
    "        self.pretrained_cnn.Mixed_7c.register_forward_hook(self.fwd_hook)\n",
    "        \n",
    "        \n",
    "    def fwd_hook(self, module,input, output):\n",
    "        #print('Inside ' + self.__class__.__name__ + ' forward')\n",
    "        self.mixed_7c_output = output\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.pretrained_cnn(x)\n",
    "        last_layer_avg_act = nn.functional.adaptive_avg_pool2d(self.mixed_7c_output,(1,1)).view(x.shape[0],2048)\n",
    "        return last_layer_avg_act\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resize image\n",
    "def process_image(path):\n",
    "    im = cv2.imread(path)\n",
    "    im = im.astype(np.float32) / 255\n",
    "    im = cv2.resize(im, (299, 299))\n",
    "    im = np.rollaxis(im, axis=2)\n",
    "    return im\n",
    "\n",
    "#Extract activations on set of images\n",
    "def extract_activations(pretrained_cnn,image_set):\n",
    "    activations = []\n",
    "    \n",
    "    for im in image_set:\n",
    "        activations.append(pretrained_cnn(im.unsqueeze(0).cuda()).detach().cpu())\n",
    "    activations = np.stack(activations,axis=0)\n",
    "    return activations\n",
    "        \n",
    "\n",
    "#Calcuate distance between the source and target distributions\n",
    "def calculate_score(images1_path,images2_path):\n",
    "    images1 = []\n",
    "    images2 = []\n",
    "    pretrained_cnn = EvaluateCycleGAN().cuda()\n",
    "    for im1,im2 in zip(glob.glob(images1_path),glob.glob(images2_path)):\n",
    "        image1 = process_image(im1)\n",
    "        image2 = process_image(im2)\n",
    "        images1.append(image1)\n",
    "        images2.append(image2)\n",
    "\n",
    "    images1 = torch.from_numpy(np.stack(images1,axis=0))\n",
    "    images2 = torch.from_numpy(np.stack(images2,axis=0))\n",
    "    activations1 = np.squeeze(extract_activations(pretrained_cnn,images1))\n",
    "    activations2 = np.squeeze(extract_activations(pretrained_cnn,images2))\n",
    "    mu1 = np.mean(activations1,axis=0)\n",
    "    mu2 = np.mean(activations2,axis=0)\n",
    "\n",
    "    sigma1 = np.cov(activations1, rowvar=False)\n",
    "    sigma2 = np.cov(activations2, rowvar=False)\n",
    "\n",
    "\n",
    "    sum_sqrd_diff = np.sum(np.power((mu1 - mu2),2.0))\n",
    "\n",
    "    meanofcovariance = linalg.sqrtm(sigma1.dot(sigma2))\n",
    "    if np.iscomplexobj(meanofcovariance):\n",
    "        meanofcovariance = meanofcovariance.real\n",
    "    eval_metric = sum_sqrd_diff + np.trace(sigma1 + sigma2 - 2.0 * meanofcovariance)\n",
    "    return eval_metric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cells validate the metric on real and synthetic datasets. Note that the number of samples for testing need to be much larger than what was used below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118.337727101751\n"
     ]
    }
   ],
   "source": [
    "#Get baseline score when comparing distributions from same domain\n",
    "images1_path = 'datasets/horse2zebra/trainA/*'\n",
    "images2_path = 'datasets/horse2zebra/testA/*'\n",
    "baseline_score1 = calculate_score(images1_path,images2_path)\n",
    "print(baseline_score1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264.70388711809017\n",
      "259.46644586806303\n"
     ]
    }
   ],
   "source": [
    "#Get the cross domain score when comparing distributions of the different domains\n",
    "images1_path = 'datasets/horse2zebra/trainB/*'\n",
    "images2_path = 'datasets/horse2zebra/testA/*'\n",
    "cross_domain_score1 = calculate_score(images1_path,images2_path)\n",
    "images1_path = 'datasets/horse2zebra/trainA/*'\n",
    "images2_path = 'datasets/horse2zebra/testB/*'\n",
    "cross_domain_score2 = calculate_score(images1_path,images2_path)\n",
    "print(cross_domain_score1)\n",
    "print(cross_domain_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139.6324603943376\n"
     ]
    }
   ],
   "source": [
    "#Get the score for synthetic data and compare to real from the same domain, should be closer to baseline score if distributions are similar.\n",
    "images1_path = 'results/horse2zebra_pretrained/test_latest/images/*fake*'\n",
    "images2_path = 'datasets/horse2zebra/testB/*'\n",
    "real_vs_synthetic_score1 = calculate_score(images1_path,images2_path)\n",
    "print(real_vs_synthetic_score1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
